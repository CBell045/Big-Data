{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "861cdbc9-bd8b-48fa-ad0f-b646c7a5b97b",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Data Pipelines\n",
    "#### Silicon Slayers\n",
    "\n",
    "Source: [Databricks](https://docs.databricks.com/en/getting-started/data-pipeline-get-started.html#:~:text=A%20data%20pipeline%20implements%20the,data%20that%20users%20can%20consume)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1b2359d0-b29d-4afa-b956-44aff07a8900",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### What is a data pipeline? \n",
    "Data pipelines are a process for moving data from sources (like a UI/Application) to targets (like a data warehouse). \n",
    "\n",
    "Data is extracted from the source, \"flows\" through the pipeline and neccesary transformations, and is loaded into the target. \n",
    "\n",
    "A key feature of data pipelines is automation; data can be loaded in batches or in (near) real time. \n",
    "\n",
    "### What is ETL? \n",
    "A common abbreviation is ETL, which stands for Extract, Transform, Load. ELT is also becoming more popular with cloud warehouses. \n",
    "\n",
    "### What are common ETL Tools? \n",
    "- Apache (Airflow, Kafka, Spark)  \n",
    "- dbt (Data Build Tool)  \n",
    "- Informatica  \n",
    "\n",
    "- AWS Glue  \n",
    "- Google Cloud Dataflow  \n",
    "- Microsoft Azure Data Factory  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%md\n",
    "For our pipeline, we are going to break out the different steps into different notebooks. \n",
    "\n",
    "Why keep them seperate? This allows our code to be more modular and, in real organizations, for different teams to work on seperate parts of the process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0c4c710-31d8-487d-bf90-eaaf15b2a81c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[3]: <pyspark.sql.streaming.query.StreamingQuery at 0x7fc515071ca0>"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, StructType, StructField\n",
    "\n",
    "# Define variables used in the code below\n",
    "file_path = \"/databricks-datasets/songs/data-001/\"\n",
    "table_name = \"raw_song_data\"\n",
    "checkpoint_path = \"/tmp/pipeline_get_started/_checkpoint/song_data\"\n",
    "\n",
    "schema = StructType(\n",
    "  [\n",
    "    StructField(\"artist_id\", StringType(), True),\n",
    "    StructField(\"artist_lat\", DoubleType(), True),\n",
    "    StructField(\"artist_long\", DoubleType(), True),\n",
    "    StructField(\"artist_location\", StringType(), True),\n",
    "    StructField(\"artist_name\", StringType(), True),\n",
    "    StructField(\"duration\", DoubleType(), True),\n",
    "    StructField(\"end_of_fade_in\", DoubleType(), True),\n",
    "    StructField(\"key\", IntegerType(), True),\n",
    "    StructField(\"key_confidence\", DoubleType(), True),\n",
    "    StructField(\"loudness\", DoubleType(), True),\n",
    "    StructField(\"release\", StringType(), True),\n",
    "    StructField(\"song_hotnes\", DoubleType(), True),\n",
    "    StructField(\"song_id\", StringType(), True),\n",
    "    StructField(\"start_of_fade_out\", DoubleType(), True),\n",
    "    StructField(\"tempo\", DoubleType(), True),\n",
    "    StructField(\"time_signature\", DoubleType(), True),\n",
    "    StructField(\"time_signature_confidence\", DoubleType(), True),\n",
    "    StructField(\"title\", StringType(), True),\n",
    "    StructField(\"year\", IntegerType(), True),\n",
    "    StructField(\"partial_sequence\", IntegerType(), True)\n",
    "  ]\n",
    ")\n",
    "\n",
    "(spark.readStream\n",
    "  .format(\"cloudFiles\")\n",
    "  .schema(schema)\n",
    "  .option(\"cloudFiles.format\", \"csv\")\n",
    "  .option(\"sep\",\"\\t\")\n",
    "  .load(file_path)\n",
    "  .writeStream\n",
    "  .option(\"checkpointLocation\", checkpoint_path)\n",
    "  .trigger(availableNow=True)\n",
    "  .toTable(table_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE OR REPLACE TABLE\n",
    "    artists (\n",
    "        artist_id STRING,\n",
    "        artist_lat DOUBLE,\n",
    "        artist_long DOUBLE,\n",
    "        artist_location STRING,\n",
    "        artist_name STRING,\n",
    "        processed_time TIMESTAMP\n",
    "        );\n",
    "\n",
    "INSERT INTO artists\n",
    "    SELECT DISTINCT\n",
    "        artist_id,\n",
    "        artist_latitude,\n",
    "        artist_longitude,\n",
    "        artist_location,\n",
    "        artist_name,\n",
    "        current_timestamp()\n",
    "    FROM raw_song_data\n",
    "    WHERE artist_id IS NOT NULL;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "%sql \n",
    "CREATE OR REPLACE TABLE\n",
    "    songs (\n",
    "        song_id STRING,\n",
    "        title STRING,\n",
    "        artist_id STRING,\n",
    "        year INT,\n",
    "        duration DOUBLE,\n",
    "        song_popularity DOUBLE,\n",
    "        loudness DOUBLE,\n",
    "        processed_time TIMESTAMP\n",
    "        );\n",
    "\n",
    "INSERT INTO songs\n",
    "    SELECT DISTINCT\n",
    "        song_id,\n",
    "        title,\n",
    "        artist_id,\n",
    "        year,\n",
    "        duration,\n",
    "        song_hotnes,\n",
    "        loudness,\n",
    "        current_timestamp()\n",
    "    FROM raw_song_data\n",
    "    WHERE song_id IS NOT NULL;"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 3742078295958070,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Pipelines",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
